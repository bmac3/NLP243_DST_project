{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6720d30-82e7-45c6-839f-a8342b3a0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "MAX_LENGTH = 1024\n",
    "INPUT_SOS = '<|context|>'\n",
    "INPUT_EOS = '<|endofcontext|>'\n",
    "OUTPUT_SOS = '<|belief|>'\n",
    "OUTPUT_EOS = '<|endofbelief|>'\n",
    "UNK_TOKEN = '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e49a5a-dff4-4cc0-8357-3cf98981911b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n",
      "GPU usage:\n",
      "  memory.used memory.free\n",
      "0    4733 MiB   19535 MiB\n",
      "1    4733 MiB   19535 MiB\n",
      "2    4733 MiB   19535 MiB\n",
      "3   20026 MiB    4242 MiB\n",
      "4   15209 MiB    9059 MiB\n",
      "5    4033 MiB   20235 MiB\n",
      "Returning GPU5 with 20235 free MiB\n",
      "using GPU id: 5\n"
     ]
    }
   ],
   "source": [
    "# picking the most free GPU resource as cuda device\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "\n",
    "\n",
    "def get_free_gpu():\n",
    "    gpu_stats = subprocess.check_output(\n",
    "        [\"nvidia-smi\", \"--format=csv\", \"--query-gpu=memory.used,memory.free\"]\n",
    "    )\n",
    "    gpu_df = pd.read_csv(\n",
    "        StringIO(gpu_stats.decode(\"utf-8\")),\n",
    "        names=[\"memory.used\", \"memory.free\"],\n",
    "        skiprows=1,\n",
    "    )\n",
    "    print(\"GPU usage:\\n{}\".format(gpu_df))\n",
    "    gpu_df[\"memory.free\"] = gpu_df[\"memory.free\"].map(\n",
    "        lambda x: int(x.rstrip(\" MiB\"))\n",
    "    )\n",
    "    idx = gpu_df[\"memory.free\"].idxmax()\n",
    "    print(\n",
    "        \"Returning GPU{} with {} free MiB\".format(\n",
    "            idx, gpu_df.iloc[idx][\"memory.free\"]\n",
    "        )\n",
    "    )\n",
    "    return idx\n",
    "\n",
    "\n",
    "cmd = \"export CUDA_VISIBLE_DEVICES=1,2,3,4,5,6\"\n",
    "os.popen(cmd)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    free_gpu_id = get_free_gpu()\n",
    "    print(f\"using GPU id: {free_gpu_id}\")\n",
    "    torch.cuda.set_device(free_gpu_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0a3166-9a67-48b7-b311-7688161c86c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resources/gpt2/train.history_belief') as fp:\n",
    "    raw_train_text = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "add0dce6-cba5-43fc-af2b-cf3e0392fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_text = raw_train_text.replace('<|endofcontext|>', ' <|endofcontext|>')\n",
    "raw_train_text = raw_train_text.replace('<|endoftext|>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "092b364f-ba75-41ba-ab78-af439c17d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = raw_train_text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88dcbcf5-e381-4aaa-9578-b52f58e3be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = []\n",
    "beliefs = []\n",
    "\n",
    "for text in train_text:\n",
    "    split_index = text.find('<|belief|>')  \n",
    "    input_text.append(text[:split_index-1].split())\n",
    "    beliefs.append(text[split_index:].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ed757e-4ae0-42dd-88b9-7f59f4443537",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(data={'input_text': input_text, 'beliefs': beliefs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e664b86-cb76-46d2-970d-1bf406befc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {}\n",
    "        self.n_words = 0\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e15cd9-b590-43fa-80b3-182d326f7431",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lang = Lang('input_lang')\n",
    "output_lang = Lang('output_lang')\n",
    "for word in raw_train_text.split():\n",
    "    input_lang.addWord(word)\n",
    "    output_lang.addWord(word)\n",
    "input_lang.addWord(UNK_TOKEN)\n",
    "output_lang.addWord(UNK_TOKEN)\n",
    "input_lang.EOS = INPUT_EOS\n",
    "output_lang.EOS = OUTPUT_EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b26468c7-4903-470c-9add-ed93104a3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b823675d-362f-4f50-94d9-f8ce1ab0591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a41a8a-1555-4d4b-a2a5-547f5204efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68f7600b-73bb-44e6-8e74-51363d175d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index.get(word, lang.word2index[UNK_TOKEN]) for word in sentence]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(lang.word2index[lang.EOS])\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2213275e-935f-44bf-af67-12a18bb972af",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[output_lang.word2index[OUTPUT_SOS]]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == output_lang.word2index[OUTPUT_EOS]:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86e10149-e2c8-47ea-ace3-f37e5ce61d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2deb16be-98ad-45b2-8f7f-2d96eb934ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tuples = [t[1:] for t in train_data.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15dfcd6a-ebdd-4f5e-aaf2-38871667b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_tuples))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2fc3484-e6e1-4f94-b73e-0221ef6b7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e10a8c7-7105-4e9a-9005-a625521a328b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[output_lang.word2index[OUTPUT_SOS]]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == output_lang.word2index[OUTPUT_EOS]:\n",
    "                decoded_words.append(OUTPUT_EOS)\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "    \n",
    "def belief_to_state_list(belief):\n",
    "    belief_list = [token for token in belief if token not in [OUTPUT_SOS, OUTPUT_EOS]]\n",
    "    belief_list = [slot.split() for slot in ' '.join(belief_list).split(',')]\n",
    "    return belief_list\n",
    "def belief_to_state_dict(belief):\n",
    "    belief_list = belief_to_state_list(belief)\n",
    "    state_dict = {}\n",
    "    for state in belief_list:\n",
    "        if len(state) < 3: continue\n",
    "        domain = state[0]\n",
    "        slot = state[1]\n",
    "        sub_slot = None\n",
    "        rest = state[2:]\n",
    "        if slot == 'book':\n",
    "            sub_slot = state[2]\n",
    "            rest = state[3:]\n",
    "        value = ' '.join(rest)\n",
    "        d = state_dict.get(domain, {})\n",
    "        if sub_slot:\n",
    "            ss = d.get(slot, {})\n",
    "            ss.update({\n",
    "                sub_slot: value\n",
    "            })\n",
    "            d.update({slot: ss})\n",
    "        else:\n",
    "            d.update({slot: value})\n",
    "        state_dict.update({domain: d})\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "def match_slot(true, pred):\n",
    "    pred_state = belief_to_state_dict(pred)\n",
    "    true_list = belief_to_state_list(true)\n",
    "    slot_matches = []\n",
    "    for i, state in enumerate(true_list):\n",
    "        if len(state) < 3: continue\n",
    "        slot_matches.append(False)\n",
    "        domain = state[0]\n",
    "        if domain not in pred_state.keys(): continue\n",
    "        \n",
    "        slot = state[1]\n",
    "        if slot not in pred_state[domain].keys(): continue\n",
    "        \n",
    "        if slot != 'book':\n",
    "            true_value = \" \".join(state[2:])\n",
    "            pred_value = pred_state[domain][slot]\n",
    "        else:\n",
    "            sub_slot = state[2]\n",
    "            if sub_slot not in pred_state[domain][slot]: continue\n",
    "            true_value = \" \".join(state[3:])\n",
    "            pred_value = pred_state[domain][slot][sub_slot]\n",
    "        \n",
    "        if true_value != pred_value: continue\n",
    "        slot_matches[i] = True\n",
    "            \n",
    "    all_match = sum(slot_matches) == len(true_list)\n",
    "    \n",
    "    return all_match, slot_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0d01e29-1123-460a-bbe7-f0de966a9c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resources/gpt2/val.history_belief') as fp:\n",
    "    raw_val_text = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "194fa456-fd15-4d9e-93ec-cb9f0a40b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val_text = raw_val_text.replace('<|endofcontext|>', ' <|endofcontext|>')\n",
    "raw_val_text = raw_val_text.replace('<|endoftext|>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca4a421e-f0d4-4426-b2eb-86c0b5ebbefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_text = raw_val_text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5160c21c-492c-4935-be54-9c917c584bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = []\n",
    "beliefs = []\n",
    "\n",
    "for text in val_text:\n",
    "    split_index = text.find('<|belief|>')  \n",
    "    input_text.append(text[:split_index-1].split())\n",
    "    beliefs.append(text[split_index:].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f06d217e-34ed-4176-95ea-8cdf1ccce3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.DataFrame(data={'input_text': input_text, 'beliefs': beliefs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef48f626-9c65-4258-a8a8-49cf1af24164",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tuples = [t[1:] for t in val_data.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2247c49-fe5c-46ed-ba8c-55f599b91839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    match_results = []\n",
    "    for i in range(n):\n",
    "        pair = random.choice(val_tuples)\n",
    "        # print('>', pair[0])\n",
    "        # print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        # output_sentence = ' '.join(output_words)\n",
    "        # print('<', output_words)\n",
    "        match_results.append(match_slot(pair[1], output_words))\n",
    "        # print('matching: ', match_slot(pair[1], output_words))\n",
    "        # print('')\n",
    "    print(get_accuracy(match_results))\n",
    "    \n",
    "def evaluate_valset(encoder, decoder):\n",
    "    match_results = []\n",
    "    for pair in tqdm(val_tuples):\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        match_results.append(match_slot(pair[1], output_words))\n",
    "    \n",
    "    print(get_accuracy(match_results))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "447be1e1-735d-4ab3-be2c-bd54ab46788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(results):\n",
    "    total_states = len(results)\n",
    "    total_slots = sum([len(result[1]) for result in results])\n",
    "    total_correct_states = sum([result[0] for result in results])\n",
    "    total_correct_slots = sum([sum(result[1]) for result in results])\n",
    "    return {\n",
    "        'joint_accuracy': total_correct_states / total_states,\n",
    "        'slot_accuracy': total_correct_slots / total_slots\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ebd4dbc-92c4-4401-a911-f55214752132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 24s (- 81m 54s) (100 0%) 4.8502\n",
      "0m 45s (- 74m 47s) (200 1%) 3.2326\n",
      "1m 8s (- 74m 35s) (300 1%) 3.0032\n",
      "1m 28s (- 72m 27s) (400 2%) 2.8887\n",
      "1m 50s (- 72m 2s) (500 2%) 2.7363\n",
      "2m 12s (- 71m 22s) (600 3%) 2.4808\n",
      "2m 35s (- 71m 31s) (700 3%) 2.3524\n",
      "2m 56s (- 70m 25s) (800 4%) 2.3188\n",
      "3m 16s (- 69m 36s) (900 4%) 2.2795\n",
      "3m 38s (- 69m 4s) (1000 5%) 2.1999\n",
      "3m 58s (- 68m 9s) (1100 5%) 2.3343\n",
      "4m 19s (- 67m 41s) (1200 6%) 2.0694\n",
      "4m 40s (- 67m 14s) (1300 6%) 2.1116\n",
      "5m 2s (- 67m 1s) (1400 7%) 2.2105\n",
      "5m 24s (- 66m 42s) (1500 7%) 2.2464\n",
      "5m 45s (- 66m 10s) (1600 8%) 2.2196\n",
      "6m 6s (- 65m 40s) (1700 8%) 2.0445\n",
      "6m 26s (- 65m 6s) (1800 9%) 2.0447\n",
      "6m 46s (- 64m 30s) (1900 9%) 2.2229\n",
      "7m 7s (- 64m 8s) (2000 10%) 2.0060\n",
      "7m 28s (- 63m 44s) (2100 10%) 2.0950\n",
      "7m 51s (- 63m 32s) (2200 11%) 2.1252\n",
      "8m 12s (- 63m 8s) (2300 11%) 1.8681\n",
      "8m 33s (- 62m 42s) (2400 12%) 2.0450\n",
      "8m 55s (- 62m 26s) (2500 12%) 1.8364\n",
      "9m 17s (- 62m 7s) (2600 13%) 1.5975\n",
      "9m 41s (- 62m 7s) (2700 13%) 1.6459\n",
      "10m 1s (- 61m 36s) (2800 14%) 1.5792\n",
      "10m 23s (- 61m 17s) (2900 14%) 1.7035\n",
      "10m 46s (- 61m 6s) (3000 15%) 1.7369\n",
      "11m 9s (- 60m 48s) (3100 15%) 1.7611\n",
      "11m 32s (- 60m 33s) (3200 16%) 1.5939\n",
      "11m 55s (- 60m 23s) (3300 16%) 1.7121\n",
      "12m 17s (- 60m 3s) (3400 17%) 1.4539\n",
      "12m 41s (- 59m 50s) (3500 17%) 1.7974\n",
      "13m 4s (- 59m 33s) (3600 18%) 1.6888\n",
      "13m 28s (- 59m 23s) (3700 18%) 1.7670\n",
      "13m 51s (- 59m 3s) (3800 19%) 1.6615\n",
      "14m 14s (- 58m 47s) (3900 19%) 1.5688\n",
      "14m 37s (- 58m 30s) (4000 20%) 1.6151\n",
      "15m 2s (- 58m 18s) (4100 20%) 1.9010\n",
      "15m 25s (- 58m 1s) (4200 21%) 1.4768\n",
      "15m 49s (- 57m 47s) (4300 21%) 1.5940\n",
      "16m 15s (- 57m 38s) (4400 22%) 1.4918\n",
      "16m 42s (- 57m 32s) (4500 22%) 1.6391\n",
      "17m 8s (- 57m 22s) (4600 23%) 1.3768\n",
      "17m 32s (- 57m 7s) (4700 23%) 1.7301\n",
      "17m 56s (- 56m 49s) (4800 24%) 1.5806\n",
      "18m 21s (- 56m 33s) (4900 24%) 1.7865\n",
      "18m 44s (- 56m 13s) (5000 25%) 1.6861\n",
      "19m 7s (- 55m 51s) (5100 25%) 1.7625\n",
      "19m 32s (- 55m 38s) (5200 26%) 1.6712\n",
      "19m 58s (- 55m 23s) (5300 26%) 1.5613\n",
      "20m 21s (- 55m 1s) (5400 27%) 1.5883\n",
      "20m 44s (- 54m 40s) (5500 27%) 1.7415\n",
      "21m 8s (- 54m 21s) (5600 28%) 1.6476\n",
      "21m 32s (- 54m 2s) (5700 28%) 1.4676\n",
      "21m 55s (- 53m 39s) (5800 28%) 1.5851\n",
      "22m 18s (- 53m 19s) (5900 29%) 1.5732\n",
      "22m 40s (- 52m 54s) (6000 30%) 1.6523\n",
      "23m 2s (- 52m 31s) (6100 30%) 1.4023\n",
      "23m 25s (- 52m 8s) (6200 31%) 1.5951\n",
      "23m 50s (- 51m 50s) (6300 31%) 1.6134\n",
      "24m 11s (- 51m 25s) (6400 32%) 1.4890\n",
      "24m 33s (- 51m 1s) (6500 32%) 1.6319\n",
      "24m 58s (- 50m 42s) (6600 33%) 1.2060\n",
      "25m 23s (- 50m 24s) (6700 33%) 1.4620\n",
      "25m 45s (- 50m 1s) (6800 34%) 1.4976\n",
      "26m 9s (- 49m 39s) (6900 34%) 1.5603\n",
      "26m 28s (- 49m 10s) (7000 35%) 1.3978\n",
      "26m 50s (- 48m 46s) (7100 35%) 1.4106\n",
      "27m 13s (- 48m 24s) (7200 36%) 1.5091\n",
      "27m 36s (- 48m 2s) (7300 36%) 1.4399\n",
      "27m 59s (- 47m 39s) (7400 37%) 1.5029\n",
      "28m 22s (- 47m 17s) (7500 37%) 1.5744\n",
      "28m 47s (- 46m 58s) (7600 38%) 1.4565\n",
      "29m 10s (- 46m 36s) (7700 38%) 1.3928\n",
      "29m 32s (- 46m 12s) (7800 39%) 1.2751\n",
      "29m 56s (- 45m 51s) (7900 39%) 1.2824\n",
      "30m 22s (- 45m 33s) (8000 40%) 1.5931\n",
      "30m 45s (- 45m 11s) (8100 40%) 1.4651\n",
      "31m 5s (- 44m 45s) (8200 41%) 1.4766\n",
      "31m 27s (- 44m 20s) (8300 41%) 1.5066\n",
      "31m 51s (- 44m 0s) (8400 42%) 1.4032\n",
      "32m 16s (- 43m 40s) (8500 42%) 1.3796\n",
      "32m 38s (- 43m 16s) (8600 43%) 1.4560\n",
      "33m 1s (- 42m 53s) (8700 43%) 1.3096\n",
      "33m 23s (- 42m 29s) (8800 44%) 1.4201\n",
      "33m 44s (- 42m 5s) (8900 44%) 1.3968\n",
      "34m 7s (- 41m 42s) (9000 45%) 1.6069\n",
      "34m 30s (- 41m 19s) (9100 45%) 1.2926\n",
      "34m 52s (- 40m 56s) (9200 46%) 1.3549\n",
      "35m 15s (- 40m 33s) (9300 46%) 1.4305\n",
      "35m 36s (- 40m 8s) (9400 47%) 1.3074\n",
      "35m 57s (- 39m 44s) (9500 47%) 1.3188\n",
      "36m 20s (- 39m 22s) (9600 48%) 1.5256\n",
      "36m 43s (- 38m 59s) (9700 48%) 1.3162\n",
      "37m 4s (- 38m 35s) (9800 49%) 1.4560\n",
      "37m 26s (- 38m 12s) (9900 49%) 1.3719\n",
      "37m 47s (- 37m 47s) (10000 50%) 1.2429\n",
      "38m 11s (- 37m 26s) (10100 50%) 1.5151\n",
      "38m 34s (- 37m 4s) (10200 51%) 1.3737\n",
      "38m 59s (- 36m 42s) (10300 51%) 1.4756\n",
      "39m 20s (- 36m 18s) (10400 52%) 1.2741\n",
      "39m 41s (- 35m 55s) (10500 52%) 1.3601\n",
      "40m 5s (- 35m 33s) (10600 53%) 1.2739\n",
      "40m 30s (- 35m 12s) (10700 53%) 1.5160\n",
      "40m 53s (- 34m 49s) (10800 54%) 1.3668\n",
      "41m 17s (- 34m 28s) (10900 54%) 1.5484\n",
      "41m 41s (- 34m 6s) (11000 55%) 1.3887\n",
      "42m 5s (- 33m 45s) (11100 55%) 1.4316\n",
      "42m 28s (- 33m 22s) (11200 56%) 1.5677\n",
      "42m 51s (- 33m 0s) (11300 56%) 1.4748\n",
      "43m 14s (- 32m 37s) (11400 56%) 1.4118\n",
      "43m 39s (- 32m 16s) (11500 57%) 1.4581\n",
      "44m 3s (- 31m 54s) (11600 57%) 1.4587\n",
      "44m 27s (- 31m 32s) (11700 58%) 1.4574\n",
      "44m 49s (- 31m 8s) (11800 59%) 1.2441\n",
      "45m 10s (- 30m 44s) (11900 59%) 1.3295\n",
      "45m 34s (- 30m 23s) (12000 60%) 1.4922\n",
      "45m 59s (- 30m 1s) (12100 60%) 1.4052\n",
      "46m 23s (- 29m 39s) (12200 61%) 1.3259\n",
      "46m 46s (- 29m 16s) (12300 61%) 1.3657\n",
      "47m 8s (- 28m 53s) (12400 62%) 1.4706\n",
      "47m 30s (- 28m 30s) (12500 62%) 1.5426\n",
      "47m 52s (- 28m 6s) (12600 63%) 1.3755\n",
      "48m 14s (- 27m 43s) (12700 63%) 1.4393\n",
      "48m 35s (- 27m 20s) (12800 64%) 1.2590\n",
      "48m 58s (- 26m 57s) (12900 64%) 1.3845\n",
      "49m 20s (- 26m 34s) (13000 65%) 1.3107\n",
      "49m 45s (- 26m 12s) (13100 65%) 1.5425\n",
      "50m 6s (- 25m 48s) (13200 66%) 1.4129\n",
      "50m 27s (- 25m 25s) (13300 66%) 1.4065\n",
      "50m 51s (- 25m 2s) (13400 67%) 1.4843\n",
      "51m 16s (- 24m 41s) (13500 67%) 1.5908\n",
      "51m 39s (- 24m 18s) (13600 68%) 1.5032\n",
      "52m 0s (- 23m 54s) (13700 68%) 1.2647\n",
      "52m 23s (- 23m 32s) (13800 69%) 1.2157\n",
      "52m 46s (- 23m 9s) (13900 69%) 1.3445\n",
      "53m 9s (- 22m 47s) (14000 70%) 1.4032\n",
      "53m 29s (- 22m 23s) (14100 70%) 1.2751\n",
      "53m 51s (- 21m 59s) (14200 71%) 1.3216\n",
      "54m 13s (- 21m 36s) (14300 71%) 1.4853\n",
      "54m 37s (- 21m 14s) (14400 72%) 1.2811\n",
      "54m 59s (- 20m 51s) (14500 72%) 1.3327\n",
      "55m 21s (- 20m 28s) (14600 73%) 1.3682\n",
      "55m 44s (- 20m 5s) (14700 73%) 1.3255\n",
      "56m 8s (- 19m 43s) (14800 74%) 1.2246\n",
      "56m 31s (- 19m 21s) (14900 74%) 1.3549\n",
      "56m 52s (- 18m 57s) (15000 75%) 1.2870\n",
      "57m 17s (- 18m 35s) (15100 75%) 1.4660\n",
      "57m 40s (- 18m 12s) (15200 76%) 1.4453\n",
      "58m 2s (- 17m 49s) (15300 76%) 1.2950\n",
      "58m 25s (- 17m 27s) (15400 77%) 1.4582\n",
      "58m 49s (- 17m 4s) (15500 77%) 1.3843\n",
      "59m 12s (- 16m 41s) (15600 78%) 1.3404\n",
      "59m 33s (- 16m 18s) (15700 78%) 1.3841\n",
      "59m 56s (- 15m 56s) (15800 79%) 1.3848\n",
      "60m 17s (- 15m 32s) (15900 79%) 1.3673\n",
      "60m 39s (- 15m 9s) (16000 80%) 1.3168\n",
      "61m 0s (- 14m 46s) (16100 80%) 1.4178\n",
      "61m 21s (- 14m 23s) (16200 81%) 1.2784\n",
      "61m 43s (- 14m 0s) (16300 81%) 1.3918\n",
      "62m 5s (- 13m 37s) (16400 82%) 1.2783\n",
      "62m 25s (- 13m 14s) (16500 82%) 1.2182\n",
      "62m 47s (- 12m 51s) (16600 83%) 1.3079\n",
      "63m 10s (- 12m 29s) (16700 83%) 1.2048\n",
      "63m 33s (- 12m 6s) (16800 84%) 1.3861\n",
      "63m 55s (- 11m 43s) (16900 84%) 1.1616\n",
      "64m 16s (- 11m 20s) (17000 85%) 1.3971\n",
      "64m 38s (- 10m 57s) (17100 85%) 1.2541\n",
      "65m 0s (- 10m 34s) (17200 86%) 1.3897\n",
      "65m 21s (- 10m 12s) (17300 86%) 1.3686\n",
      "65m 43s (- 9m 49s) (17400 87%) 1.5808\n",
      "66m 4s (- 9m 26s) (17500 87%) 1.3114\n",
      "66m 26s (- 9m 3s) (17600 88%) 1.2059\n",
      "66m 49s (- 8m 41s) (17700 88%) 1.2872\n",
      "67m 12s (- 8m 18s) (17800 89%) 1.3663\n",
      "67m 34s (- 7m 55s) (17900 89%) 1.3792\n",
      "67m 56s (- 7m 32s) (18000 90%) 1.2734\n",
      "68m 18s (- 7m 10s) (18100 90%) 1.2801\n",
      "68m 40s (- 6m 47s) (18200 91%) 1.2771\n",
      "69m 1s (- 6m 24s) (18300 91%) 1.3159\n",
      "69m 23s (- 6m 2s) (18400 92%) 1.3167\n",
      "69m 44s (- 5m 39s) (18500 92%) 1.3533\n",
      "70m 5s (- 5m 16s) (18600 93%) 1.0954\n",
      "70m 27s (- 4m 53s) (18700 93%) 1.3828\n",
      "70m 49s (- 4m 31s) (18800 94%) 1.3198\n",
      "71m 11s (- 4m 8s) (18900 94%) 1.3349\n",
      "71m 33s (- 3m 45s) (19000 95%) 1.3833\n",
      "71m 56s (- 3m 23s) (19100 95%) 1.2560\n",
      "72m 20s (- 3m 0s) (19200 96%) 1.2695\n",
      "72m 43s (- 2m 38s) (19300 96%) 1.2899\n",
      "73m 6s (- 2m 15s) (19400 97%) 1.3840\n",
      "73m 28s (- 1m 53s) (19500 97%) 1.4059\n",
      "73m 50s (- 1m 30s) (19600 98%) 1.2131\n",
      "74m 12s (- 1m 7s) (19700 98%) 1.1879\n",
      "74m 36s (- 0m 45s) (19800 99%) 1.1883\n",
      "74m 59s (- 0m 22s) (19900 99%) 1.1991\n",
      "75m 23s (- 0m 0s) (20000 100%) 1.1022\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 20000, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2f74a09-0b4a-485f-ae18-7f5894b011a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_accuracy': 0.0075, 'slot_accuracy': 0.1947565543071161}\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a176033-ba5d-4ca7-a773-61b8cad09492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7375/7375 [06:52<00:00, 17.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_accuracy': 0.008949152542372881, 'slot_accuracy': 0.19583711521006722}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_valset(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "aaf31f0e-d2b7-49ce-84d2-116df6dec087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f2786954-b4c8-4006-be29-d713eb2fcb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hotel': {'name': 'not mentioned',\n",
       "  'area': 'not mentioned',\n",
       "  'parking': 'yes',\n",
       "  'pricerange': 'cheap',\n",
       "  'stars': 'not mentioned',\n",
       "  'internet': 'not mentioned',\n",
       "  'type': 'hotel',\n",
       "  'book': {'stay': '2', 'day': 'tuesday', 'people': '6'}}}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "belief_to_state_dict(train_data['beliefs'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9a57de41-8cf1-451c-853c-e0e5d7e610df",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_belief_sample = ['<|belief|>', 'attraction', 'type', 'college', ',', 'attraction', 'name', 'christ', 'college', ',', 'attraction', 'area', 'not', 'mentioned', '<|endofbelief|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "182cb394-8e26-4613-a2a3-c20fd8ebb6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attraction': {'type': 'college',\n",
       "  'name': 'christ college',\n",
       "  'area': 'not mentioned'}}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "belief_to_state_dict(val_belief_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2718eb6f-d4f0-4690-8175-ec1eb6f4e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_belief_true_sample = ['<|belief|>', 'attraction', 'type', 'college', ',', 'attraction', 'name', 'christ', 'college', ',', 'attraction', 'area', 'not', 'mentioned', '<|endofbelief|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c19272cd-3acd-45f8-adf3-ccc4e8ee7234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "e4cd0fa7-f289-4342-a836-dc1e52be2f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, [True, True, True])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_slot(val_belief_true_sample, val_belief_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f22bc-356d-4c6d-8003-c1a52553ea29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit (conda)",
   "language": "python",
   "name": "python3812jvsc74a57bd04a64bfe93dbb51924a5ad8d7e9312f968a417a773494ea590cc93068d261664b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
